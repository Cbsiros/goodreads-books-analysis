# ğŸ“š Goodreads Book Scraper & Analyzer

A two-stage data pipeline that scrapes detailed metadata from Goodreads' ["Best Books Ever"](https://www.goodreads.com/list/show/1.Best_Books_Ever) list, cleans and transforms it into structured datasets, and prepares it for data analysis, visualization, and machine learning workflows.

---

## ğŸ” Project Overview

This project collects and prepares real-world book data by:

- ğŸŒ **Scraping Goodreads** for book-level details  
- ğŸ§¼ **Cleaning and transforming** raw metadata into analysis-ready format  
- ğŸ§  **Engineering features** like `book_age` and `author_popularity`  
- ğŸ“Š **Normalizing genres** into a one-hot encoded matrix  
- ğŸ§ª **Generating EDA summaries** to assess data quality and structure  

---

## ğŸ“ Output Files

| File                                | Description                                                                 |
|-------------------------------------|-----------------------------------------------------------------------------|
| `goodreads-books-raw.csv`           | Raw scraped metadata for each book (overwritten on every scrape run)       |
| `goodreads-books-clean.csv`         | Cleaned, structured dataset with `book_id`, feature engineering, and imputed values |
| `goodreads-book-genres-clean.csv`   | One-hot encoded genre matrix aligned to `book_id`                           |

---

## ğŸ”§ Full Pipeline Features

### âœ… Stage 1: Web Scraping (`data-collection.ipynb`)

- Collects links from multiple Goodreads list pages  
- Extracts metadata: title, author, genres, rating, reviews, description, language, series, and cover image  
- Implements:
  - Retry logic for stability  
  - Custom User-Agent and request throttling  
  - Structured `Book` dataclass for clean data modeling  
  - Logging for tracking progress and errors  

### âœ… Stage 2: Cleaning, Transformation, and EDA (`data-cleaning.ipynb`)

- Assigns a unique `book_id` to every book  
- Cleans whitespace in `title`, `author`, `description`  
- Converts `num_pages` and `publication_year` to integers  
- Removes duplicates based on `title` and `author`  
- Imputes missing `language` values using the `langid` library  
- Normalizes and one-hot encodes `genres` into a separate matrix  
- Engineers:
  - `book_age` from publication year  
  - `author_popularity` based on author frequency  
- Includes a custom `print_summary()` EDA tool for diagnostics  

---

## ğŸ› ï¸ Technologies Used

- Python 3.x  
- Requests  
- BeautifulSoup4  
- Pandas / NumPy / SciPy  
- langid  
- Dataclasses  
- Jupyter Notebook  

---

## âš™ï¸ How to Use

1. **Clone the repository**  
2. *(Optional)* Create and activate a virtual environment  
3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
4. **Run the notebooks in order**:
    `data-collection.ipynb`
    `data-cleaning.ipynb`

Output files will be saved to the ./data/ directory

---

## âš ï¸ Notes

- The raw data file (`goodreads-books-raw.csv`) is overwritten on every run to ensure freshness  
- This project follows respectful scraping practices:
  - Custom User-Agent  
  - Throttled requests with random delays  
- Always respect [Goodreadsâ€™ Terms of Use](https://www.goodreads.com/about/terms)  

---

## ğŸ“ˆ Next Steps

Planned enhancements include:

- ğŸ§  NLP-based topic modeling and sentiment analysis  
- ğŸ“Š Power BI or interactive dashboard for visual exploration  
- ğŸ” Clustering authors or genres by themes or popularity  
- ğŸ¤– Book recommendation engine using reader preferences  
